{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMaVN15Upff1zOhduPgCAqL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Javierxd1/Analisis-de-sentimientos-en-comentarios/blob/main/Aplicaci%C3%B3n%3A%20Analisis%20de%20sentimiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "G1WjWjPb4_CH"
      },
      "outputs": [],
      "source": [
        "##Librerias requeridas\n",
        "!pip install transformers\n",
        "!pip install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import io\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from transformers import pipeline\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "X3vuo0-K627J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import sendfile\n",
        "#Flujo de actividades\n",
        "\n",
        "#Pipeline de an치lisis de sentimiento\n",
        "sentiment_pipeline = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"Javierxd17/roberta-base-bne-SentimentAnalysis-cursoNLP-Platzi\"\n",
        ")"
      ],
      "metadata": {
        "id": "LcPwbjOP7Eao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NER Pipeline\n",
        "ner_pipeline = pipeline(\n",
        "    \"ner\",\n",
        "    model=\"mrm8488/bert-spanish-cased-finetuned-ner\",\n",
        "    tokenizer=\"mrm8488/bert-spanish-cased-finetuned-ner\"\n",
        ")"
      ],
      "metadata": {
        "id": "p5fyVpH-7iTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcionalidades\n",
        "\n",
        "# Funci칩n para limpiar el texto\n",
        "def clean(text):\n",
        "    # Eliminar textos entre corchetes (ej.: etiquetas)\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "\n",
        "    # Eliminar URLs\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "    # Eliminar etiquetas HTML\n",
        "    text = re.sub(r'<.*?>+', '', text)\n",
        "\n",
        "    # Eliminar espacios extras al inicio y final\n",
        "    text = text.strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "aOxgGtwt7ufu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reconstrucci칩n de entidades\n",
        "def reconstruct_entity(ner_tokens):\n",
        "    \"\"\"\n",
        "    Reconstruye una entidad a partir de una lista de tokens de NER.\n",
        "    Si un token empieza con \"##\", se une al token anterior sin espacio.\n",
        "    \"\"\"\n",
        "    entity = \"\"\n",
        "    for token in ner_tokens:\n",
        "        word = token['word']\n",
        "        if word.startswith(\"##\"):\n",
        "            entity += word[2:]\n",
        "        else:\n",
        "            if entity:\n",
        "                entity += \" \" + word\n",
        "            else:\n",
        "                entity += word\n",
        "    return entity"
      ],
      "metadata": {
        "id": "gu0UOaoC75pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci칩n para procesar la salida del NER y agrupar tokens en entidades completas\n",
        "def process_ner_output(ner_results):\n",
        "    \"\"\"\n",
        "    Procesa la salida del NER ignorando el tipo de entidad y devuelve un diccionario\n",
        "    con una 칰nica clave \"entities\" cuyo valor es la entidad reconstruida a partir de todos los tokens.\n",
        "    \"\"\"\n",
        "    # Reconstruir la entidad a partir de todos los tokens de la lista\n",
        "    combined = reconstruct_entity(ner_results)\n",
        "    return {\"entities\": combined}"
      ],
      "metadata": {
        "id": "XcwU4ODB8j1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci칩n para analizar un solo texto\n",
        "def analyze_text(input_text):\n",
        "    input_text = clean(input_text)\n",
        "    sentiment = sentiment_pipeline(input_text)\n",
        "    ner_results = ner_pipeline(input_text)\n",
        "    processed_ner = process_ner_output(ner_results)\n",
        "    return sentiment, processed_ner"
      ],
      "metadata": {
        "id": "yg0eNecI8sRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci칩n para analizar un archivo CSV\n",
        "def analyze_csv(file_obj):\n",
        "    df = pd.read_csv(file_obj.name)\n",
        "    if \"review_body\" not in df.columns:\n",
        "        return \"Error: No se encontr칩 la columna 'review_body'.\", None, None\n",
        "    texts = df[\"review_body\"].astype(str).tolist()\n",
        "\n",
        "    # Limpiar cada rese침a\n",
        "    cleaned_texts = [clean(text) for text in texts]\n",
        "\n",
        "    # Obtener an치lisis de sentimiento y NER para cada rese침a limpia\n",
        "    sentiments = [sentiment_pipeline(text) for text in cleaned_texts]\n",
        "    ner_all = [process_ner_output(ner_pipeline(text)) for text in cleaned_texts]\n",
        "\n",
        "    # Extraer las entidades detectadas (valor) de cada rese침a\n",
        "    ner_words = []\n",
        "    for ner_result in ner_all:\n",
        "        # ner_result es un diccionario con la clave \"entities\"\n",
        "        ner_words.append(ner_result[\"entities\"])\n",
        "\n",
        "    # Unir todas las entidades en un solo string\n",
        "    combined_ner_text = \" \".join(ner_words)\n",
        "\n",
        "    # Generar wordcloud basado en las entidades detectadas\n",
        "    wc = WordCloud(stopwords=STOPWORDS, background_color=\"white\", width=800, height=400).generate(combined_ner_text)\n",
        "    buf = io.BytesIO()\n",
        "    wc.to_image().save(buf, format=\"PNG\")\n",
        "    buf.seek(0)\n",
        "\n",
        "    # Convertir a imagen PIL para que Gradio lo pueda mostrar\n",
        "    image = Image.open(buf)\n",
        "\n",
        "    return sentiments, ner_all, image"
      ],
      "metadata": {
        "id": "9fyqeHne9OVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tablero de aplicaci칩n"
      ],
      "metadata": {
        "id": "JEZWu4-u9hgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kO86d9ui9jz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "dUHjjPT2-Lsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(theme=gr.themes.Citrus()) as demo:\n",
        "    gr.Markdown(\"## Aplicaci칩n de An치lisis de Rese침as de un e-commerce 游닍游댌\")\n",
        "\n",
        "    with gr.Tab(\"An치lisis de Texto\"):\n",
        "        gr.Markdown(\"### Ingrese una rese침a de texto\")\n",
        "        text_input = gr.Textbox(label=\"Texto de Rese침a\", placeholder=\"Escribe aqu칤 la rese침a...\")\n",
        "        sentiment_output = gr.JSON(label=\"An치lisis de Sentimiento\")\n",
        "        ner_output = gr.JSON(label=\"Entidades Reconocidas (NER)\")\n",
        "        analyze_btn = gr.Button(\"Analizar Texto\")\n",
        "        analyze_btn.click(analyze_text, inputs=text_input, outputs=[sentiment_output, ner_output])\n",
        "\n",
        "    with gr.Tab(\"An치lisis de CSV\"):\n",
        "        gr.Markdown(\"### Suba un archivo CSV con una columna 'review_body'\")\n",
        "        csv_input = gr.File(label=\"Archivo CSV\")\n",
        "        csv_sentiment_output = gr.JSON(label=\"An치lisis de Sentimiento (por Rese침a)\")\n",
        "        csv_ner_output = gr.JSON(label=\"Entidades Reconocidas (por Rese침a)\")\n",
        "        wc_output = gr.Image(label=\"WordCloud (Entidades)\")\n",
        "        analyze_csv_btn = gr.Button(\"Analizar CSV\")\n",
        "        analyze_csv_btn.click(analyze_csv, inputs=csv_input, outputs=[csv_sentiment_output, csv_ner_output, wc_output])"
      ],
      "metadata": {
        "id": "uO7KjrxR9gy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lanzar la aplicaci칩n\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "Qwr5t3Mj_-A6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}